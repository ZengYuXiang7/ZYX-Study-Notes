# 12.13 SparCode论文精读

双塔匹配之外：学习稀疏可检索的交叉交互进行推荐

提问样例：你觉得哪里开销大，哪里可能存在不合理的地方



### 大背景存在挑战：

它面临两个主要的挑战，包括有限的特征交互能力和在线服务中的准确性降低。

现有的方法试图设计新颖的后期交互而不是点积，但它们仍然无法支持复杂的特征交互或失去检索效率。



### 提出的解决办法：

我们提出了一种新的匹配范式Spar Code，它不仅支持复杂的特征交互，还支持高效的检索。

复杂特征交互，高效检索

1. an all-to-all interaction module to model fine-grained query-item interactions：一个全对全的交互模块，用于建模细粒度的查询-项交互。

2. Besides, we design a discrete code-based sparse inverted index jointly trained with the model to achieve effective and efficient model inference：此外，我们设计了一个基于离散码的稀疏倒排索引与模型联合训练，以实现有效且高效的模型推断。

结果表明，Spar Code在保留与双塔模型**相同检索效率**的同时，显著提高了候选项匹配的**准确率**。





双塔模型是？

![image-20231213221615977](C:\Users\39712\AppData\Roaming\Typora\typora-user-images\image-20231213221615977.png)

As shown in Figure 1(a), a two-tower model uses dual-encoders (i.e. query and item encoders) to obtain the query1 and item representations separately and obtains the final score by simple dot product or cosine computations.如图1 ( a )所示，双塔模型使用双编码器(即查询和项目编码器)分别获得查询1和项目表示，并通过简单的点积或余弦计算获得最终分数。



为了进行推理，项目嵌入可以预先计算和缓存，而只有用户嵌入是在线计算的。通过利用缓存的项目嵌入和对快速近似最近邻( Approximate Nearest Neighbor，ANN )搜索的支持，双塔匹配已被证明在实际应用中具有良好的工业实践。



双塔模型的大缺点：

1. 缺乏特征交互表达能力：两个塔之间只有一个点积交互，导致对查询和项目之间细粒度特征交互的建模能力有限。虽然点积是一种很好的特征交互方法，但它并不总是最优的，尤其是在内容特征丰富的情况下。
2. 在线学习压力大：在许多工业场景中，候选项目池的规模非常大，由于推理时间的限制，穷举比较所有候选项目变得不切实际。ANN检索方法( e.g . , HNSW )已经被用于构建索引和加快检索速度，但遗憾的是这可能会降低召回率，因为模型和索引通常不是端到端的训练。





为了增强特征交互能力，全互换交互模块使用单个表达能力编码器捕获所有查询特征和所有项目特征之间的细粒度交互。

好处：它允许不同形式的编码器结构( e.g. Self- Attention 、MLPs、Cross Net )，可以学习到查询和项(即,早期融合)之间更细粒度和更有预测性的特征交互。

细粒度的特征交互提高了模型的容量，从而提高了准确率，正如之前的研究[ 20、25 ]所报告的那样。



**Challenge1**：然而，与双塔模型相比，查询项编码的特性使得现有的ANN方法很难用于有效的检索，使其不切实际。



为了加快模型推理速度，一个直接的解决方法是预先计算用户-项目对的评分并进行缓存。

因此，Spar Code引入了稀疏检索中广泛使用的稀疏倒排索引。

**Challenge2**：

1. 用户数量太大，无法穷举，导致预计算代价太大。
2. 每个用户(索引)对应大量的物品，带来了极大的存储压力。

解决办法：Spar Code利用矢量量化( VQ )作为全向交互和稀疏倒排索引之间的桥梁

即查询被量化为一系列离散的代码和相应的代码表示，其中代码代替查询作为索引，代码表示用于所有到所有的交互。由于编码数量可控且远小于查询次数，缓解了索引数量大的问题。

进一步地，Spar Code设计了一个受控的稀疏得分函数，使得每个指标只保存最相关的候选，大大缓解了存储压力。





综上，我们从模型结构和推论两个角度展示了Spar Code的优势：在模型结构上，Spar Code通过设计VQ和稀疏倒排索引(对于限制1)的链接，支持复杂形式的全对全交互和大规模候选对象的高效top - k检索。Spar Code将全互换交互直接引入模型结构，显著增强了特征交互的能力，而不是使用全互换交互模型间接( e.g.知识蒸馏( KD )) [ 3 ] )或使用无参数交互方式(如科尔贝特)。此外，稀疏的倒排索引还得到了诸如Elastic Search等成熟的搜索工具的支持，保证了在工业应用中的可用性。



对于模型推理，Spar Code减少了模型训练和推理之间的差距，因为模型和索引结构都是端到端(对于极限2 )训练的。在Spar Code的索引结构中，索引为code，对应于code和候选项的得分。查询和代码之间的映射以及评分是在模型训练过程中学习的，而不是在Faiss等ANN库中独立地进行后训练。因此，我们减少了这一阶段的性能下降，这也在我们的实验中得到了经验验证(第4.4节)。



总而言之，Spar Code作为一种基于全对全交互的检索范式，在保持推理效率的同时，借助增强的特征交互达到了提高准确率的目的。虽然本文主要关注推荐系统，但Spar Code有潜力扩展到其他任务，如跨模态检索。我们在两个公开的数据集上进行了大量的实验，结果表明Spar Code的精度明显高于双塔模型( 4.2节)，并且与基于ANN的双塔模型( 4.4节)相当。我们的贡献总结如下。



### 核心贡献

Spar Code是第一个支持复杂形式的全向交互和可控稀疏倒排索引的稀疏检索框架

Spar Code将查询转换为离散代码，从而使预先计算的分数成为可能。此外，Spar Code以稀疏的倒排索引结构实现高效检索，具有成熟的索引工具支持产业部署。



![image-20231213223450021](C:\Users\39712\AppData\Roaming\Typora\typora-user-images\image-20231213223450021.png)





词法分析和量化器旨在获得查询的多个离散表示，支持稀疏的倒排索引以保持效率

基于全对全交互的评分器增强了查询和项目之间的交互，以提高准确性。

Two-tower model: $\quad$                 score $=E_1(q) \circ E_2(c)$,
All-to-all interaction model: $\quad$ score $=E(q, c)$,
SparCode: $\quad$                               score $=\sum_k E\left(\mathcal{T}_k(q), c\right)$,

T ( · )指的是词法分析和量化器，将q转换为令牌嵌入并寻找编码和替代编码表示。

通过这些等式，我们突出了Spar Code的设计动机。

采用点积评分的两个塔模型(即:式中: 1 )是为了支持基于嵌入的高效检索。

全局性交互模型(即:式中: 2 )支持任意高级编码器进行细粒度的特征交互。

通常Eq . 2由于其推理效率低而被用于少数候选人的排名。

SparCode (即:式中: 3 )，基于Eq . 2、将总体得分函数定义为每个编码与候选人之间的得分之和。

这意味着任意查询可以被代码替换，共享一个代码的可管理大小的词汇表。将编码看作单词，文本检索中广泛使用的倒排索引[ 28 ]可以很容易地迁移到推荐任务中。通过这个定义，Spar Code不仅引入了强大的全对全交互，而且实现了类似于稀疏检索的高效检索。





![image-20231216173513958](C:\Users\39712\AppData\Roaming\Typora\typora-user-images\image-20231216173513958.png)

建模阶段。Spar Code支持先进的全对全交互编码器，提供了比双塔匹配更好的特征交互能力，双塔匹配只支持点积等无参数交互。此外，Spar Code的量化器允许在不同的查询表示中共享子嵌入，而在双塔模型中每个查询的表示是独立的。

推断阶段。如图3.4 ( a )和( b )的右边部分所示，我们总结了不同之处：( 1 )缓存内容。Spar Code不缓存项目嵌入，而是选择性地缓存预先计算好的(代码,项)分值。( 2 )缓存结构。Spar Code缓存是基于稀疏码的倒排索引的稀疏哈希表，而双塔匹配缓存矩阵的项嵌入或其他索引结构取决于ANN的设置。



Spar Code采用稀疏倒排索引，推理复杂度为O ( 1 )

量化器通过离散化将查询令牌嵌入转化为共享代码及其表示。



3.2.1 分词器。

​	为了能够支持稀疏倒排索引，受到稀疏检索的启发，我们首先将查询$q$编码为多个标记嵌入。分词器的作用是将查询表示为$K_u$个标记。具体而言，在推荐中（即用户），将查询编码为$K_u$个标记，表示用户的多个兴趣。

​	查询可能包含图像、文本、序列信息或类别特征。统一地，我们将查询$q \in Q$和候选项$c \in I$表示为一系列嵌入，即，
$$
\begin{aligned}
& H^u=\left[h_1^u, h_2^u, \ldots, h_L^u\right], H^u \in \mathbb{R}^{L \times D}, \\
& H^v=\left[h_1^v, h_2^v, \ldots, h_P^v\right], H^v \in \mathbb{R}^{P \times D},
\end{aligned}
$$
其中$H^u$和$H^v$分别是给定的$q$和$c$的$L$和$P$嵌入；$D$是$H^u$和$H^v$中每个嵌入的维度。 然后，我们将第$i$个标记的表示形式形式化如下：
$$
T_i^u=\operatorname{Tokenizer}\left(H^u\right) \in \mathbb{R}^{D^T},
$$
其中$D^T$是一个标记的嵌入维度，取决于分词器的设置，通常等于$D$。分词器的具体形式取决于给定的任务和特征，例如，如果查询是历史用户点击的序列，分词器可以选择自GRU [4]、自注意力 [12, 17]、胶囊网络 [17]等中进行选择。

​	类似地，我们将一个项目表示为$K_c$个标记$T^c \in \mathbb{R}^{K_c \times D^T}$。



3.2.2 量化器。

​	对于文本匹配任务，尽管查询的数量很大，它们共享相同的标记表（即词汇表），这限制了倒排索引中的索引数量与标记表的大小相同。然而，查询标记嵌入是密集的，并且在查询之间不共享，这使得无法建立合理数量的索引。因此，在本节中，量化器通过离散化将查询标记嵌入转换为共享的代码及其表示。

​	在矢量量化[29]中，码书是指一系列编号的矢量，其编号称为码。量化是将查询输入并通过查找码书返回码和相应的矢量，从而使得任意查询共享码书。通过利用VQ，我们将标记嵌入量化为离散代码。我们构建了$M$个码书$C \in \mathbb{R}^{N \times \frac{D^T}{M}}$，每个大小为$N$，即包含$N$个有序嵌入。对于$T_i^u$，我们将其分割为$M$个子嵌入$T_i^{u,(m)}$并通过以下方式更新它：
$$
\begin{aligned}
\widetilde{T}_i^{u,(m)} & =Q u antizer\left(T_i^{u,(m)}, C^{(m)}\right) \\
& =C_k^{(m)}, \text { where } k=\arg \min _j\left\|C_j^{(m)}-T_i^{u,(m)}\right\|_2,
\end{aligned}
$$
其中$C^{(m)}$是第$m$个码书，$C_k^m$是它的第$k$个嵌入；量化器表示从给定码书中查找最相似的子标记嵌入，相似性的定义取决于两个子嵌入之间的欧几里得距离。因此，我们得到完整更新的标记嵌入：
$$
\widetilde{T}_i^u=\operatorname{Concat}\left(\widetilde{T}_i^{u,(1)}, \widetilde{T}_i^{u,(2)}, \cdots, \widetilde{T}_i^{u,(M)}\right) .
$$

​	我们使用$M$个被替换的子嵌入的索引来组合相应的离散代码。例如，在图2中，假设$M=2$，并且第2个和第$N$个子嵌入分别取自$C^{(1)}$和$C^{(2)}$，那么离散代码就是$(2, N)$。

![image-20231218165727885](C:\Users\39712\AppData\Roaming\Typora\typora-user-images\image-20231218165727885.png)

​	有关码书设计有两个考虑因素。首先，每个码书的大小$N$不应设置得太大，因为过大的码书会影响我们的“量化器”的速度。其次，$N$不应太小，因为我们需要足够的模型容量来表示不同的查询。基于上述考虑，我们讨论$M$和$N$的选择。离散代码的数量最多为$N \times N \times \cdots \times N=N^M$。如果$M$取1，无论有多少查询，最终只会有$N$个不同的查询嵌入。为了充分表示不同的查询，$N$趋向于较大，但这会迅速增加参数数量，可能降低量化速度。如果$M$大于或等于2，就有可能用较少的参数和更快的量化速度实现足够多的查询。

​	此外，由于“arg min”是一个不可微的操作，在这里存在一个非常重要的优化问题。具体而言，原始标记嵌入$T_i^u$无法从更新后的标记嵌入$\widetilde{T}_i^u$中获取梯度，最终导致以前的参数（例如，分词器）未被更新。我们将在第3.2.4节中描述相应的模型训练解决方案。



3.2.3 全互连基于评分的评分器。

​	作为一个无参数操作，两塔模型的点积完成了查询和项目之间的特征交互和评分，这可能限制了模型的表达能力。

​	与之前的两塔模型的变体不同，我们设计了一个参数化的、可学习的评分器，支持查询和项目之间的复杂交互，称为全互连基于评分的评分器。

​	提出的评分器不限制特征交互的具体形式，无论是显式的（内积、FM [26]、CrossNet [32]、Attention [18, 30]）还是隐式的（例如DNN）。例如，我们结合了内积和多层感知机（MLP）以给出一个混合评分函数：
$$
S_i=\operatorname{MLPs}\left(\left[\operatorname{sg}\left[\widetilde{T}_i^u\right] \odot T_1^i ; \cdots ; s g\left[\widetilde{T}_i^u\right] \odot T_{K_c}^i\right]\right), i \in\{1,2, \cdots, K\}
$$
其中 $S_i \in \mathcal{R}^1$ 是码和候选项 $c$ 之间的匹配得分；$s g[\cdot]$ 代表停止梯度操作。由于码书和模型的其余部分是分别优化的，引入 $s g[\cdot]$ 是为了避免影响码书的参数。此外，查询由 $K_u$ 个标记嵌入表示，上述评分函数将分别获得 $K_u$ 个分数。

考虑到查询或标记仅与部分候选项相关，我们定义稀疏分数和最终分数如下：
$$
\begin{aligned}
& \hat{y}_i=\operatorname{ReLU}\left(S_i+\mathbf{b}\right), \\
& f(q, c)=\hat{y}=\sum_{i=1}^K \hat{y}_i,
\end{aligned}
$$
其中 $\mathbf{b}$ 是一个可学习的用于训练的偏置。
	评分函数，特别是对应于式（10）的部分，虽然简单但对于稀疏索引是关键的。ReLU 中的偏置项 $\mathbf{b}$ 是确定是否将相关分数 $\hat{y}_i$ 设置为 0 的阈值。如果 $\hat{y}_i$ 等于 0，则在线服务中无需提前缓存 $\hat{y}_i$（详见第 3.3 节的详细信息）。



3.2.4 优化。

​	为了使量化过程的训练更加稳定和快速，我们使用指数移动平均（Exponential Moving Average，EMA）来更新码书，并使用反向传播来更新模型的其余部分，类似于[24]。在每个小批次中，码书和模型的其余参数通过相应的方法进行更新。

模型训练。

​	这里的模型不包括码书。匹配任务是最重要的目标，SparCode 采用了采样 softmax 损失进行训练，如下所示：
$$
\mathcal{L}_{\text{Match}}(q, \mathcal{I}) = \sum_{c \in \mathcal{I}_{\text{pos}}} \log \frac{\exp\left(\hat{y}_c\right)}{\exp\left(\hat{y}_c\right)+\sum_{\hat{c} \in \mathcal{I}_{\text{neg}}} \exp\left(\hat{y}_{\hat{c}}\right)},
$$
其中 $\mathcal{I}_{\text{pos}}$ 和 $\mathcal{I}_{\text{neg}}$ 分别表示对于 $q$ 进行采样的正样本和负样本。 正如前面提到的，arg min 是一个不可微的操作，阻碍了梯度的传播，导致一些参数（如分词器或嵌入表）无法得到更新。为了更新这些参数并使训练更加稳定，我们引入了Commit损失，如下所示：
$$
\mathcal{L}_{\text{Commit}}(q) = \sum_{i=1}^K \sum_{m=1}^M\left\|T_i^{u,(m)}-s g\left[\widetilde{T}_i^{u,(m)}\right]\right\|_2^2 .
$$

因此，最终的损失是：
$$
\mathcal{L}(q, \mathcal{I}) = \mathcal{L}_{\text{Match}}(q, \mathcal{I}) + \lambda \mathcal{L}_{\text{Commit}}(q),
$$
其中 $\lambda$ 是一个超参数，通常设置为1或0.25。



码书更新。

​	遵循[24]，我们通过EMA来更新码书，其中码书中的嵌入被迭代更新，采用自身和映射到它的标记嵌入的组合。假设在第 $s$ 个小批次的码书 $C^{(m)}$ 中，有一系列 $n_k^{(s)}$ 子嵌入，最近的子嵌入是 $C_k^{(m)}$，我们可以将 $C_k^{(m)}$ 更新为：
$$
\begin{aligned}
\mathcal{N}_k^{(s)} & :=\mathcal{N}_k^{(s-1)} * \gamma+n_k^{(s)} *(1-\gamma), \\
\mathcal{V}_k^{(s)} & :=\mathcal{V}_k^{(s-1)} * \gamma+\sum_{j=1}^{n_k^{(s)}} T^{u,(m)}(j) *(1-\gamma), \\
C_k^{(m),(s)} & :=\frac{\mathcal{V}_k^{(s)}}{\mathcal{N}_k^{(s)}},
\end{aligned}
$$
其中 $\gamma$ 是一个调整码书更新速率的超参数。



3.3 索引和检索

​	通过分词器和量化器，查询被转换为$K_u$个代码，并通过基于全对全交互的评分器与每个项目$c$具有得分$s_c^{code}$。此外，如果缓存所有（代码，项目）对的分数，存储成本可能会不可接受。在大多数情况下，查询只与部分项目高度相关，这使得稀疏倒排索引成为可能，因为只需为每个代码保留几个前相关项目的得分。

​	受到稀疏检索的启发，并受倒排索引的效率吸引，我们为SparCode设计了一种稀疏倒排索引机制。我们使用0作为阈值来决定是否在推断时存储得分。我们重写Eq. 10 以在训练时使用可控偏置而不是偏置项，称为“稀疏性控制”如下：
$$
\hat{y}_i=\operatorname{ReLU}\left(S_i+\widetilde{\mathbf{b}}\right) \text {. }
$$

根据延迟要求和内存约束，我们调整Eq. 15中的$\widetilde{\mathbf{b}}$以确定索引的稀疏性。

![image-20231218135055695](C:\Users\39712\AppData\Roaming\Typora\typora-user-images\image-20231218135055695.png)

​	图3(b)说明了SparCode的在线服务过程。右侧和蓝色部分显示了如何缓存得分，即每个代码与候选项的得分被稀疏缓存。重要的是要注意这些得分是预先计算的。

​	在线提供服务时，首先通过分词器获取标记嵌入，然后通过码书查找代码。然后，从缓存中加载相应的项目分数和经过筛选的候选项目集。例如，在图3(a)中，如果代码是$(1,1)$和$(1,2)$，我们读取得分集合$\left\{s_9^{(1,1)}, s_{24}^{(1,1)}, s_9^{(1,2)}, s_{13}^{(1,2)}, s_{25}^{(1,2)}\right\}$并获得合并的项目集$\left\{c_9, c_{24}, c_{13}, c_{25}\right\}$。最后，使用Eq. 11获得最终得分，具有最高得分的项目被视为推荐结果。



格式：(2, N),  (1, 2, 3, 5, 7, 8, N)



通过倒排索引来提升检索效率，然后通过PQ进行embedding压缩

主要用来对embedding进行基于MIPS的ANN检索

主要是把在线计算的双塔向量内积，换成了提前离线计算好的单塔(e.g. MLP)分数。

这样就实现了相似度计算函数上的精度提升。





## 知乎网友

在索引构建时，sparCode存储的是query 'token' - item score。比如query = 'xxx'，tokenizer得到几个token embedding, quantizer得到这几个token embedding对应的code。



用code作为key，去查KV cache得到每个token x item的分数，多个token查到的item-score合并得到topk。每个token x item对应的分数是提前算好的。



算分可以用一个MLP，输入[token embedding, item embedding], 输出分数。对于大量的无效或者中低频token x item pair，文中给出了一个简单的稀疏化方案。



sparCode主要是构建索引时提前计算了token-doc分数，这个分数可以算的很复杂，因为是离线算好的。

因为query得到的token embedding要做量化, token x item pair要做稀疏化，精度肯定会下降。

所以实际系统中，全交互带来的性能提升，是否能打平或者超过量化&稀疏化这两者的损失，还要实验确认。











## 过程理解：

$N=3$的情况，并确保每个码本$C^{(m)}$有3个向量：

$$
C^{(1)} = \begin{bmatrix} 
0.3 & 0.2 & 0.6 \\
0.2 & 0.5 & 0.7 \\
0.1 & 0.4 & 0.8 \\
\end{bmatrix}



C^{(2)} = \begin{bmatrix} 
0.1 & 0.5 & 0.8 \\
0.3 & 0.6 & 0.4 \\
0.2 & 0.4 & 0.7 \\
\end{bmatrix}
$$


现在，每个码本中有3个向量。

接下来，我们按照之前的步骤进行分割和量化：

1. **分割为子嵌入：**

$$
T_i^{u,(1)} = [0.4, 0.1, 0.7]\\
T_i^{u,(2)} = [0.4, 0.1, 0.7]
$$

2. **嵌入量化：**

   - 对于子嵌入$T_i^{u,(1)}$：

     $$
     \widetilde{T}_i^{u,(1)} = \text{Quantizer}(T_i^{u,(1)}, C^{(1)}) = C_k^{(1)} = [0.3, 0.2, 0.6]
     $$

   - 对于子嵌入$T_i^{u,(2)}$：

     $$
     \widetilde{T}_i^{u,(2)} = \text{Quantizer}(T_i^{u,(2)}, C^{(2)}) = C_k^{(2)} = [0.1, 0.5, 0.8]
     $$

3. **合并离散代码：**
   $$
   \widetilde{T}_i^u = [\widetilde{T}_i^{u,(1)}, \widetilde{T}_i^{u,(2)}] = [0.3, 0.2, 0.6, 0.1, 0.5, 0.8]
   $$

这样，每个子嵌入都经过量化器得到了对应的离散代码，形成了最终的离散代码表示$\widetilde{T}_i^u$。





假设我们有两个候选项 $c_1$ 和 $c_2$，它们的标记嵌入分别为：

$$
T_1^{c} = \begin{bmatrix} 
0.1 & 0.3 & 0.5 \\
0.2 & 0.4 & 0.6 \\
0.3 & 0.5 & 0.7 \\
\end{bmatrix}
$$

$$
T_2^{c} = \begin{bmatrix} 
0.5 & 0.2 & 0.8 \\
0.4 & 0.6 & 0.1 \\
0.7 & 0.9 & 0.2 \\
\end{bmatrix}
$$

我们之前得到的离散代码是：

$$
\widetilde{T}_i^u = [0.3, 0.2, 0.6, 0.1, 0.5, 0.8]
$$
接下来，我们将这个离散代码输入全互连基于评分的评分器。假设我们使用ReLU作为激活函数，得到两个候选项的匹配得分：

因此，离散代码中的每个元素需要与候选项的标记嵌入矩阵的每个元素分别相乘，这样才能得到匹配得分。

具体而言，对于候选项 $c_1$：

$$
\begin{align*}
S_i^{(c_1)} &= \text{ReLU}([0.3 \times 0.1, 0.2 \times 0.3, 0.6 \times 0.5, 0.1 \times 0.2, 0.5 \times 0.4, 0.8 \times 0.6]) \\
&= \text{ReLU}([0.03, 0.06, 0.3, 0.02, 0.2, 0.48]).
\end{align*}
$$
对于候选项 $c_2$：

$$
\begin{align*}
S_i^{(c_2)} &= \text{ReLU}([0.3 \times 0.5, 0.2 \times 0.2, 0.6 \times 0.8, 0.1 \times 0.4, 0.5 \times 0.6, 0.8 \times 0.1]) \\
&= \text{ReLU}([0.15, 0.04, 0.48, 0.04, 0.3, 0.08]).
\end{align*}
$$
接下来，我们融合这两个得分，并加上一个偏置项 $\mathbf{b} = 0.1$：

$$
\hat{y}_i = \text{ReLU}(\sum_{j=1}^{2} S_i^{(c_j)} + 0.1).
$$
这样得到的 $\hat{y}_i$ 即为查询和每个候选项之间的匹配得分。
